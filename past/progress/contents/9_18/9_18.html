<html>
<head>   
<link rel= "icon"; sizes="144x144"； href="../../../../img/planet.png">
<link rel="stylesheet" type="text/css" href="../../../../css/general.css">
<link href="https://fonts.googleapis.com/css?family=Josefin+Sans:300" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Press+Start+2P" rel="stylesheet">
<meta
name="viewport"
content="width=device-width,initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" />
    <title>
        September 18 
    </title>

    </head>
<body>
    <p class="time">
    September 18
    </p>
    <p class="content">
    Project concepts:</br>
            1. Use probably genetic programming and autoconstruction to build an AI program which constructs artificial  worlds with alternative physical laws and virtual reality environments. To be detailed, the program takes different arrangements of artificial world environments as inputs and generate new object arrangements. </br>
    *What should be the inputs for creating new physics laws? </br></br>
    2. The program takes attributes of existing animals including appearances, metal states, movement compositions(mechanics), habits, roles in the biosphere and etc. as inputs and generate new life forms.
    It would be great if we could make this program a future-fish-predictor.</br> </br> 
    
    *What is the most difficult question that could be solved by AI tech?</br>
    Jona: If a program can solve relatively easy problems, it probably also works well on harder problems.
</br></br></br>
    Cluster Meeting:</br>
        1. Computational power: PC ok if run one problem with 1000+ samples. If train, larger server will be needed.
</br>
2. Hard part of genetic programming -> how to plug parameters into.</br></br></br>

<a href="https://arxiv.org/pdf/1606.01540.pdf"
   class="link">OpenAI</a>
</br>
Reinforcement learning assumes that there is an agent that is situated in an environment. Each step, the agent takes an action, and it receives an observation and reward from the environment. </br>
OpenAI breaks the agent object’s experience down into a series of episodes. In each episode, the agent’s initial state is randomly sampled from a distribution, and the interaction proceeds til the environment reaches a terminal state. The goal in episodic reinforcement learning is to maximize the expectation of total reward per episode, and to achieve a high level of performance in as few episodes as possible.
</br></br>
Environments:</br>
• Classic control and toy text: small-scale tasks from the RL literature.</br>
• Algorithmic: perform computations such as adding multi-digit numbers and reversing sequences.</br>
• Atari: classic Atari games, with screen images or RAM as input, uses the Arcade Learning Environment .</br>
• Board games: currently, the game of Go on 9x9 and 19x19 boards, where the Pachi engine serves as an opponent.</br>
• 2D and 3D robots: control a robot in simulation. These tasks use the MuJoCo physics engine, which was designed for fast and accurate robot simulation.</br></br>
*Due to its specific requirement of feedback system and environment tyoes, not a feasible way to construct neither artificial objects nor physic laws.
</p>
</br></br>


     <p class="button">           
            <a href="../9_12/9_12.html">
                <-  PRE           
            </a>
                |<a href="../../index.html">
                BACK           
            </a>
                |
            <a href="../9_26/9_26.html">
                NEXT  ->
            </a>
    </p>
    </body>
</html>
