<html>
<head>   
<link rel= "icon"; sizes="144x144"； href="img/icon.png">
<link rel="stylesheet" type="text/css" href="css/index.css">

<link href="https://fonts.googleapis.com/css?family=Josefin+Sans:300" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Press+Start+2P" rel="stylesheet">
<meta
name="viewport"
content="width=device-width,initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" />
    <title>
        Research in AI    
    </title>

    </head>
<body>
    <p class="time">
    </br>
    Last update: September 17th, 2018
    </p>

    <div class="current">
    Status Report:
        </br><p class="content">
    
            1.Cluster meeting with Jona and Elijah at Hampshire, Tuesday September 18th. Jona talked about how to write programs using nerual networks&clojure.</br>
    2. 2 project concepts, one about artificial world settings/physical laws, the other about artificial life/animal behaviors.</br>
    3. OpenAI, paper about benchmark questions and autoconstruction.
    </p>
    Progress Report:
        </br><p class="content">
            Project concepts:</br>
            1. Use probably genetic programming and autoconstruction to build an AI program which constructs artificial  worlds with alternative physical laws and virtual reality environments. To be detailed, the program takes different arrangements of artificial world environments as inputs and generate new object arrangements. </br>
    *What should be the inputs for creating new physics laws? </br></br>
    2. The program takes attributes of existing animals including appearances, metal states, movement compositions(mechanics), habits, roles in the biosphere and etc. as inputs and generate new life forms.
    It would be great if we could make this program a future-fish-predictor.</br> </br> 
    
    *What is the most difficult question that could be solved by AI tech?</br>
    Jona: If a program can solve relatively easy problems, it probably also works well on harder problems.</br></br>

        1. Computational power: PC ok if run one problem with 1000+ samples. If train, larger server will be needed.
</br>
2. Hard part of genetic programming -> how to plug parameters into.</br></br>
<a href="https://arxiv.org/pdf/1606.01540.pdf"
   class="link">OpenAI</a>
</br>
Reinforcement learning assumes that there is an agent that is situated in an environment. Each step, the agent takes an action, and it receives an observation and reward from the environment. </br>
OpenAI breaks the agent object’s experience down into a series of episodes. In each episode, the agent’s initial state is randomly sampled from a distribution, and the interaction proceeds til the environment reaches a terminal state. The goal in episodic reinforcement learning is to maximize the expectation of total reward per episode, and to achieve a high level of performance in as few episodes as possible.
</br></br>
Environments:</br>
• Classic control and toy text: small-scale tasks from the RL literature.</br>
• Algorithmic: perform computations such as adding multi-digit numbers and reversing sequences.</br>
• Atari: classic Atari games, with screen images or RAM as input, uses the Arcade Learning Environment .</br>
• Board games: currently, the game of Go on 9x9 and 19x19 boards, where the Pachi engine serves as an opponent.</br>
• 2D and 3D robots: control a robot in simulation. These tasks use the MuJoCo physics engine, which was designed for fast and accurate robot simulation.</br>

</br></br>
Benchmark Questions:</br>
1.Notice not to be language specific.

    </p>
    
    </div></br>

    </br></br>
    <div class="past">
        <p>-> <a href="past/status/index.html">Past status reports</a>
        </br>-> <a href="past/progress/index.html">Past Progress reports</a>
        </p>
    </div>
    </body>
</html>
